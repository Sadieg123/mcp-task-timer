# PROCESS.md — Active Timer Listing Feature Reflection

For this exercise, I built a `list_timers` tool in my MCP server that displays all currently running timers along with their elapsed time without stopping them. I approached this using the micro-iteration workflow, breaking the feature into small, testable steps. In Step 1, I extracted a `formatElapsed` helper to keep time formatting consistent. Step 2 was a stub tool, returning a placeholder so I could verify registration and server integration. Step 3 added handling for the empty-timers case, returning "No timers are currently running" when the Map was empty. Step 4 implemented the full logic to iterate timers, calculate elapsed time, format it, and build a dynamic message for multiple timers. Finally, Step 5 was a self-review, where I asked Claude to analyze the tool for bugs, edge cases, and non-destructive behavior.

Using micro-iteration made the workflow very manageable. Each step was small enough to review, test, and understand fully, which helped me catch potential issues early. For example, self-review consistently highlighted edge cases, like pluralization in the header and very short timers, which I might have overlooked. There were times when Claude missed small details, like handling zero timers separately, so human verification was still necessary. The browser-based tool made iteration fast and interactive — I could prompt, get code, and test immediately — whereas a CLI workflow would be slower, requiring build and restart each time. Micro-iteration and self-review are especially useful for features with multiple edge cases and user-visible output, like this timer listing tool, but for simple, single-line changes, the workflow could be overkill.

Overall, this process reinforced the value of building incrementally, verifying each step, and documenting what was learned. By the end, the `list_timers` tool worked as intended, was non-destructive, and the workflow produced clear evidence for grading.
